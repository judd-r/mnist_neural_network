{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9bfe1347",
   "metadata": {},
   "source": [
    "# Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6343a2b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, models, layers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4b147837",
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7442edff",
   "metadata": {},
   "source": [
    "## Explore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "05e24a2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train – shape (60000, 28, 28) \n",
      "X_test  – shape (10000, 28, 28) \n",
      "y_train – shape (60000,) \n",
      "y_test  – shape (10000,)\n"
     ]
    }
   ],
   "source": [
    "print(f'X_train – shape {X_train.shape} \\nX_test  – shape {X_test.shape} \\n' \n",
    "      f'y_train – shape {y_train.shape} \\ny_test  – shape {y_test.shape}') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1f885eb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(type(y_train))\n",
    "type(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "39e4db87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,\n",
       "        13,  14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,\n",
       "        26,  27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,\n",
       "        39,  40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,\n",
       "        52,  53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,\n",
       "        65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
       "        78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,\n",
       "        91,  92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103,\n",
       "       104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116,\n",
       "       117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129,\n",
       "       130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142,\n",
       "       143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
       "       156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168,\n",
       "       169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
       "       182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194,\n",
       "       195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207,\n",
       "       208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220,\n",
       "       221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n",
       "       234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246,\n",
       "       247, 248, 249, 250, 251, 252, 253, 254, 255], dtype=uint8)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5d08c858",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=uint8)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e91d6495",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 648x648 with 16 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize = (9, 9))\n",
    "\n",
    "for i in range(16):\n",
    "    plt.subplot(4, 4, i + 1)\n",
    "    plt.imshow(X_train[i], cmap=\"gray\")\n",
    "    plt.xlabel(str(y_train[i]))\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "plt.show()    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d79787ad",
   "metadata": {},
   "source": [
    "## Reshape and normalise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "566d1679",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NB: the order of the following operations makes a massive difference for the model\n",
    "# performance. In first attempt I divided X_train / 255. and then reshaped --> accuracy after epoch 20\n",
    "# was 0.1 -- in this current order – reshape, normalise – accuracy is >0.9\n",
    "\n",
    "X_train = np.reshape(X_train, (len(X_train), 28 * 28))\n",
    "X_test = np.reshape(X_test, (len(X_test), 28 * 28))\n",
    "\n",
    "X_train = X_train / 255.\n",
    "X_test = X_test / 255."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ec3b29c",
   "metadata": {},
   "source": [
    "# ML models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "131124ec",
   "metadata": {},
   "source": [
    "## 3 layers, Dense, activation function sigmoid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "570590eb",
   "metadata": {},
   "source": [
    "### Create"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "aad6d75a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO In another model, change activation function to 'relu', then normalise the output later (when?)\n",
    "# sigmoid gives output 0-1, relu 0-infinite --> not great for visualisation\n",
    "model = models.Sequential([\n",
    "    layers.Dense(32, input_shape=(784,), activation='sigmoid'),\n",
    "    layers.Dense(32, activation='sigmoid'), \n",
    "    layers.Dense(10, activation='softmax')\n",
    "    ]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "08a5b929",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss = 'sparse_categorical_crossentropy', \n",
    "    optimizer = 'adam',\n",
    "    metrics = ['accuracy']\n",
    "    ) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3dd505b",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "33840629",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "59/59 - 0s - loss: 0.1525 - accuracy: 0.9583 - val_loss: 0.1716 - val_accuracy: 0.9505\n",
      "Epoch 2/20\n",
      "59/59 - 0s - loss: 0.1488 - accuracy: 0.9586 - val_loss: 0.1684 - val_accuracy: 0.9514\n",
      "Epoch 3/20\n",
      "59/59 - 0s - loss: 0.1454 - accuracy: 0.9597 - val_loss: 0.1649 - val_accuracy: 0.9532\n",
      "Epoch 4/20\n",
      "59/59 - 0s - loss: 0.1417 - accuracy: 0.9609 - val_loss: 0.1627 - val_accuracy: 0.9529\n",
      "Epoch 5/20\n",
      "59/59 - 0s - loss: 0.1388 - accuracy: 0.9618 - val_loss: 0.1600 - val_accuracy: 0.9533\n",
      "Epoch 6/20\n",
      "59/59 - 0s - loss: 0.1353 - accuracy: 0.9624 - val_loss: 0.1587 - val_accuracy: 0.9535\n",
      "Epoch 7/20\n",
      "59/59 - 0s - loss: 0.1324 - accuracy: 0.9632 - val_loss: 0.1569 - val_accuracy: 0.9539\n",
      "Epoch 8/20\n",
      "59/59 - 0s - loss: 0.1294 - accuracy: 0.9638 - val_loss: 0.1535 - val_accuracy: 0.9549\n",
      "Epoch 9/20\n",
      "59/59 - 0s - loss: 0.1267 - accuracy: 0.9646 - val_loss: 0.1521 - val_accuracy: 0.9562\n",
      "Epoch 10/20\n",
      "59/59 - 0s - loss: 0.1239 - accuracy: 0.9652 - val_loss: 0.1499 - val_accuracy: 0.9564\n",
      "Epoch 11/20\n",
      "59/59 - 0s - loss: 0.1213 - accuracy: 0.9663 - val_loss: 0.1485 - val_accuracy: 0.9559\n",
      "Epoch 12/20\n",
      "59/59 - 0s - loss: 0.1188 - accuracy: 0.9671 - val_loss: 0.1468 - val_accuracy: 0.9580\n",
      "Epoch 13/20\n",
      "59/59 - 0s - loss: 0.1164 - accuracy: 0.9679 - val_loss: 0.1455 - val_accuracy: 0.9572\n",
      "Epoch 14/20\n",
      "59/59 - 0s - loss: 0.1140 - accuracy: 0.9684 - val_loss: 0.1437 - val_accuracy: 0.9580\n",
      "Epoch 15/20\n",
      "59/59 - 0s - loss: 0.1118 - accuracy: 0.9692 - val_loss: 0.1427 - val_accuracy: 0.9588\n",
      "Epoch 16/20\n",
      "59/59 - 0s - loss: 0.1095 - accuracy: 0.9700 - val_loss: 0.1416 - val_accuracy: 0.9584\n",
      "Epoch 17/20\n",
      "59/59 - 0s - loss: 0.1073 - accuracy: 0.9704 - val_loss: 0.1397 - val_accuracy: 0.9598\n",
      "Epoch 18/20\n",
      "59/59 - 0s - loss: 0.1055 - accuracy: 0.9708 - val_loss: 0.1391 - val_accuracy: 0.9602\n",
      "Epoch 19/20\n",
      "59/59 - 0s - loss: 0.1033 - accuracy: 0.9712 - val_loss: 0.1371 - val_accuracy: 0.9607\n",
      "Epoch 20/20\n",
      "59/59 - 0s - loss: 0.1010 - accuracy: 0.9718 - val_loss: 0.1366 - val_accuracy: 0.9603\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data = (X_test, y_test),\n",
    "    epochs = 20,\n",
    "    batch_size = 1024, # check why this number\n",
    "    verbose = 2\n",
    "    ) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2d4cc43",
   "metadata": {},
   "source": [
    "### Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "05c54870",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('../mnist_neural_network/mnist_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeb2d01d",
   "metadata": {},
   "source": [
    "## 3 layers, one Conv2d, sigmoid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a5fd2fb",
   "metadata": {},
   "source": [
    "### Create"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "75a989fc",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input 0 of layer conv2d_1 is incompatible with the layer: : expected min_ndim=4, found ndim=2. Full shape received: (None, 784)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/sy/ghzc776162l56twn948v9rv40000gn/T/ipykernel_36625/2311579152.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m model = models.Sequential([\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConv2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m784\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'sigmoid'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m# better: relu\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'sigmoid'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m#  because better precision?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'softmax'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# but needs normalisation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     ]) \n",
      "\u001b[0;32m~/.pyenv/versions/3.9.5/envs/mnist_neural/lib/python3.9/site-packages/tensorflow/python/training/tracking/base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    528\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    529\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 530\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    531\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.9.5/envs/mnist_neural/lib/python3.9/site-packages/keras/engine/sequential.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, layers, name)\u001b[0m\n\u001b[1;32m    132\u001b[0m         \u001b[0mlayers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.9.5/envs/mnist_neural/lib/python3.9/site-packages/tensorflow/python/training/tracking/base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    528\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    529\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 530\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    531\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.9.5/envs/mnist_neural/lib/python3.9/site-packages/keras/engine/sequential.py\u001b[0m in \u001b[0;36madd\u001b[0;34m(self, layer)\u001b[0m\n\u001b[1;32m    200\u001b[0m           \u001b[0;31m# and create the node connecting the current layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m           \u001b[0;31m# to the input layer we just created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 202\u001b[0;31m           \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    203\u001b[0m           \u001b[0mset_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.9.5/envs/mnist_neural/lib/python3.9/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    974\u001b[0m     \u001b[0;31m# >> model = tf.keras.Model(inputs, outputs)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    975\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_in_functional_construction_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 976\u001b[0;31m       return self._functional_construction_call(inputs, args, kwargs,\n\u001b[0m\u001b[1;32m    977\u001b[0m                                                 input_list)\n\u001b[1;32m    978\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.9.5/envs/mnist_neural/lib/python3.9/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_functional_construction_call\u001b[0;34m(self, inputs, args, kwargs, input_list)\u001b[0m\n\u001b[1;32m   1112\u001b[0m         layer=self, inputs=inputs, build_graph=True, training=training_value):\n\u001b[1;32m   1113\u001b[0m       \u001b[0;31m# Check input assumptions set after layer building, e.g. input shape.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1114\u001b[0;31m       outputs = self._keras_tensor_symbolic_call(\n\u001b[0m\u001b[1;32m   1115\u001b[0m           inputs, input_masks, args, kwargs)\n\u001b[1;32m   1116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.9.5/envs/mnist_neural/lib/python3.9/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_keras_tensor_symbolic_call\u001b[0;34m(self, inputs, input_masks, args, kwargs)\u001b[0m\n\u001b[1;32m    846\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeras_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mKerasTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_signature\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    847\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 848\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_infer_output_signature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_infer_output_signature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.9.5/envs/mnist_neural/lib/python3.9/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_infer_output_signature\u001b[0;34m(self, inputs, args, kwargs, input_masks)\u001b[0m\n\u001b[1;32m    884\u001b[0m           \u001b[0;31m# overridden).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    885\u001b[0m           \u001b[0;31m# TODO(kaftan): do we maybe_build here, or have we already done it?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 886\u001b[0;31m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_build\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    887\u001b[0m           \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.9.5/envs/mnist_neural/lib/python3.9/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_maybe_build\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2631\u001b[0m     \u001b[0;31m# Check input assumptions set before layer building, e.g. input rank.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2632\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2633\u001b[0;31m       input_spec.assert_input_compatibility(\n\u001b[0m\u001b[1;32m   2634\u001b[0m           self.input_spec, inputs, self.name)\n\u001b[1;32m   2635\u001b[0m       \u001b[0minput_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.9.5/envs/mnist_neural/lib/python3.9/site-packages/keras/engine/input_spec.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[0;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[1;32m    227\u001b[0m       \u001b[0mndim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrank\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mndim\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mndim\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin_ndim\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 229\u001b[0;31m         raise ValueError('Input ' + str(input_index) + ' of layer ' +\n\u001b[0m\u001b[1;32m    230\u001b[0m                          \u001b[0mlayer_name\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' is incompatible with the layer: '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m                          \u001b[0;34m': expected min_ndim='\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin_ndim\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input 0 of layer conv2d_1 is incompatible with the layer: : expected min_ndim=4, found ndim=2. Full shape received: (None, 784)"
     ]
    }
   ],
   "source": [
    "# TODO Wrong input shape --> need to reshape to (rows, height, width, color (1 channel))\n",
    "model = models.Sequential([\n",
    "    layers.Conv2D(32, (2, 2), input_shape=(784,), activation='sigmoid'),\n",
    "    layers.Dense(32, activation='sigmoid'), #  \n",
    "    layers.Dense(10, activation='softmax') # \n",
    "    ]) \n",
    "\n",
    "model.compile(\n",
    "    loss = 'sparse_categorical_crossentropy', # if one hot encode: categ_crossentr\n",
    "    optimizer = 'adam',\n",
    "    metrics = ['accuracy']\n",
    "    ) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fe4b53d",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aee753de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d4049c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e789d684",
   "metadata": {},
   "source": [
    "### Save"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c3f9202",
   "metadata": {},
   "source": [
    "# ML Server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "edb9b8d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# same code in ml_server.py \n",
    "# --> TODO tidy up, import from ml_server\n",
    "model = tf.keras.models.load_model('../mnist_neural_network/mnist_model.h5') \n",
    "\n",
    "model_all_layers = tf.keras.models.Model(\n",
    "    model.inputs,\n",
    "    [layer.output for layer in model.layers], # currently: 3 layers\n",
    "    )\n",
    "\n",
    "_, (X_test2, _) = tf.keras.datasets.mnist.load_data()\n",
    "X_test2 = X_test2 / 255.\n",
    "\n",
    "def get_prediction():\n",
    "    \"\"\" Return outputs (incl. y = [0-9] ?) of predict method on NN model\n",
    "        showing output for all layers\n",
    "    \"\"\"\n",
    "    index = np.random.choice(X_test2.shape[0]) # or len(X_test)?\n",
    "    image = X_test2[index, :, :] # gives random row\n",
    "    image_arr = np.reshape(image, (1, 784))\n",
    "\n",
    "    return model_all_layers.predict(image_arr), image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "66d2c345",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds, image = get_prediction()\n",
    "type(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "d9d9ecdc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "97a9195c",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.0745098 , 0.43529412, 0.73333333, 0.94901961, 0.15294118,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.11764706,\n",
       "        0.86666667, 0.99215686, 0.99215686, 0.79215686, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.12156863, 0.84313725,\n",
       "        1.        , 0.99215686, 0.67058824, 0.29019608, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.12941176, 0.85490196, 0.99215686,\n",
       "        0.94901961, 0.49411765, 0.00784314, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.60784314, 0.99215686, 0.99215686,\n",
       "        0.15294118, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.01568627, 0.74117647, 0.99215686, 0.50196078,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.65098039, 0.99215686, 0.71372549, 0.01176471,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.0627451 , 0.9254902 , 0.99215686, 0.42745098, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.48235294, 0.99215686, 0.73333333, 0.06666667, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.19215686,\n",
       "        0.96862745, 0.97647059, 0.21960784, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.46666667,\n",
       "        0.99607843, 0.65098039, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.0627451 , 0.89019608,\n",
       "        0.99215686, 0.08627451, 0.        , 0.        , 0.        ,\n",
       "        0.2627451 , 0.2627451 , 0.2627451 , 0.1254902 , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.09019608, 0.99215686,\n",
       "        0.99215686, 0.08627451, 0.        , 0.42352941, 0.82352941,\n",
       "        0.99607843, 0.99215686, 0.99215686, 0.90588235, 0.54117647,\n",
       "        0.08627451, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.09019608, 0.99215686,\n",
       "        0.99215686, 0.1254902 , 0.61568627, 0.98431373, 0.99215686,\n",
       "        0.85490196, 0.4745098 , 0.4745098 , 0.70588235, 0.99215686,\n",
       "        0.25490196, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.09019608, 0.99215686,\n",
       "        0.99215686, 0.84313725, 0.99215686, 0.9254902 , 0.4       ,\n",
       "        0.        , 0.        , 0.        , 0.18431373, 0.99215686,\n",
       "        0.54901961, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.05882353, 0.8745098 ,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.35294118, 0.        ,\n",
       "        0.        , 0.        , 0.1372549 , 0.8745098 , 0.99215686,\n",
       "        0.21568627, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.63137255,\n",
       "        0.99215686, 0.99215686, 0.90980392, 0.13333333, 0.        ,\n",
       "        0.00784314, 0.34901961, 0.87058824, 0.98823529, 0.85490196,\n",
       "        0.11372549, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.18039216,\n",
       "        0.95686275, 0.99215686, 0.9254902 , 0.47843137, 0.17647059,\n",
       "        0.65882353, 0.99215686, 0.99215686, 0.56470588, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.20392157, 0.8       , 0.99215686, 0.99215686, 0.99215686,\n",
       "        0.99607843, 0.99215686, 0.74117647, 0.02745098, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.0627451 , 0.39215686, 0.56078431, 0.74901961,\n",
       "        0.56078431, 0.25882353, 0.02352941, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ]])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "8caa8b7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[2.5365859e-02, 2.6857355e-01, 2.2476614e-03, 9.9934530e-01,\n",
       "         9.7954881e-01, 1.3455749e-02, 9.9999905e-01, 1.4542639e-03,\n",
       "         1.5541911e-04, 9.9744332e-01, 1.5572071e-02, 1.9399552e-14,\n",
       "         2.6594067e-05, 5.6022793e-01, 3.1581998e-10, 9.9908209e-01,\n",
       "         1.2506932e-02, 2.3030788e-02, 7.2479379e-01, 1.8753606e-01,\n",
       "         1.3110226e-11, 7.9846094e-09, 2.8397986e-01, 8.4071755e-03,\n",
       "         9.9816155e-01, 2.4035156e-02, 1.4937620e-09, 2.7502683e-10,\n",
       "         1.2926757e-03, 9.9987060e-01, 9.9416429e-01, 8.5951984e-01]],\n",
       "       dtype=float32),\n",
       " array([[0.66975784, 0.17144412, 0.8609518 , 0.2537238 , 0.79253596,\n",
       "         0.82655585, 0.8572259 , 0.8730975 , 0.07310054, 0.03326786,\n",
       "         0.6786599 , 0.08446527, 0.7919488 , 0.1446825 , 0.207629  ,\n",
       "         0.9745549 , 0.67576694, 0.27516162, 0.25720587, 0.31216398,\n",
       "         0.39845067, 0.77755415, 0.40128672, 0.72044164, 0.41667062,\n",
       "         0.64996636, 0.39695334, 0.62985384, 0.05339524, 0.18532813,\n",
       "         0.8897513 , 0.8939754 ]], dtype=float32),\n",
       " array([[9.7339135e-01, 2.4579707e-05, 1.8284371e-03, 7.6489954e-04,\n",
       "         2.6584503e-03, 1.4765331e-03, 1.2016317e-02, 1.8779748e-03,\n",
       "         1.4876795e-04, 5.8125951e-03]], dtype=float32)]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(preds))\n",
    "preds\n",
    "# returns the three layers, 1 + 2 have 32 nodes each, 3 has 10 (y = 0-9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "3edcb6ad",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'plot'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/sy/ghzc776162l56twn948v9rv40000gn/T/ipykernel_11355/331427099.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumbers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumber\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'float32'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m#plt.subplot(row, col, i + 1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m         \u001b[0;31m#plt.imshow(number * np.ones((8, 8, 3)).astype('float32'))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;31m#plt.xticks([])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'plot'"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 2304x288 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#TODO figure out fig, ax in a for loop? because st.pyplot() deprecated\n",
    "\n",
    "import requests\n",
    "\n",
    "URI = 'http://127.0.0.1:5000/'\n",
    "\n",
    "response = requests.post(URI, data={})\n",
    "response = json.loads(response.text)\n",
    "preds = response.get('prediction')\n",
    "image = response.get('image')\n",
    "image = np.reshape(image, (28, 28))\n",
    "\n",
    "fig, ax = plt.subplots(3, 1, figsize=(32,4))\n",
    "for layer, pred in enumerate(preds):\n",
    "    numbers = np.squeeze(np.array(pred)) # removes additional dimensionality of the data\n",
    "\n",
    "    #plt.figure(figsize=(32, 4))\n",
    "    #if layer == 2: # my final layer\n",
    "     #   row = 1\n",
    "      #  col = 10\n",
    "    #else:\n",
    "     #   row = 2\n",
    "      #  col = 16\n",
    "\n",
    "    for i, number in enumerate(numbers):\n",
    "        ax.plot(number * np.ones((8, 8, 3)).astype('float32'))  #plt.subplot(row, col, i + 1)\n",
    "        #plt.imshow(number * np.ones((8, 8, 3)).astype('float32'))\n",
    "        #plt.xticks([])\n",
    "        #plt.yticks([])\n",
    "\n",
    "       # if layer == 2:\n",
    "        #    plt.xlabel(str(i), fontsize=40)\n",
    "\n",
    "    plt.subplots_adjust(wspace=0.05, hspace=0.05)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    st.text(f'Layer {layer + 1} (colour range: black == 0, white == 1')\n",
    "    st.pyplot(fig) #st.pyplot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8e10178",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
